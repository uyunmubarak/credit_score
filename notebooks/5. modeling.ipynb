{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.1 Perform Forward Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import library for modeling\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "#load configuration\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_dataset_path': '../data/raw/Loan_default.csv',\n",
       " 'dataset_path': '../data/output/data.pkl',\n",
       " 'predictors_set_path': '../data/output/predictors.pkl',\n",
       " 'response_set_path': '../data/output/response.pkl',\n",
       " 'train_path': ['../data/output/X_train.pkl', '../data/output/y_train.pkl'],\n",
       " 'test_path': ['../data/output/X_test.pkl', '../data/output/y_test.pkl'],\n",
       " 'data_train_path': '../data/output/training_data.pkl',\n",
       " 'data_train_binned_path': '../data/output/bin_training_data.pkl',\n",
       " 'crosstab_list_path': '../data/output/list_crosstab.pkl',\n",
       " 'WOE_table_path': '../data/output/WOE_table.pkl',\n",
       " 'IV_table_path': '../data/output/IV_table.pkl',\n",
       " 'WOE_map_dict_path': '../data/output/WOE_map_dict.pkl',\n",
       " 'X_train_woe_path': '../data/output/X_train_woe.pkl',\n",
       " 'response_variable': 'Default',\n",
       " 'test_size': 0.2,\n",
       " 'numeric_col': ['Age',\n",
       "  'Income',\n",
       "  'LoanAmount',\n",
       "  'MonthsEmployed',\n",
       "  'NumCreditLines',\n",
       "  'InterestRate',\n",
       "  'LoanTerm',\n",
       "  'DTIRatio'],\n",
       " 'categoric_col': ['Education',\n",
       "  'EmploymentType',\n",
       "  'MaritalStatus',\n",
       "  'HasMortgage',\n",
       "  'HasDependents',\n",
       "  'LoanPurpose',\n",
       "  'HasCoSigner'],\n",
       " 'num_of_bins': 5,\n",
       " 'num_of_cv': 10,\n",
       " 'scoring': 'recall',\n",
       " 'forward_models_path': '../models/forward_models.pkl',\n",
       " 'best_predictors_path': '../models/best_predictors_path.pkl',\n",
       " 'best_model_path': '../models/best_model.pkl',\n",
       " 'best_model_summary_path': '../models/best_model_summary.pkl',\n",
       " 'pdo': 20,\n",
       " 'score_ref': 200,\n",
       " 'odds_ref': 30,\n",
       " 'scorecards_path': '../models/scorecards.pkl',\n",
       " 'points_map_dict_path': '../models/points_map_dict.pkl',\n",
       " 'X_points_path': '../models/X_points.pkl',\n",
       " 'X_train_points_path': '../models/X_train_points.pkl',\n",
       " 'score_path': '../models/score_path.pkl',\n",
       " 'cutoff_score': 150,\n",
       " 'columns_': ['Age_binned',\n",
       "  'DTIRatio_binned',\n",
       "  'Education',\n",
       "  'EmploymentType',\n",
       "  'HasCoSigner',\n",
       "  'HasDependents',\n",
       "  'HasMortgage',\n",
       "  'Income_binned',\n",
       "  'InterestRate_binned',\n",
       "  'LoanAmount_binned',\n",
       "  'LoanPurpose',\n",
       "  'LoanTerm_binned',\n",
       "  'MaritalStatus',\n",
       "  'MonthsEmployed_binned',\n",
       "  'NumCreditLines_binned']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_data = utils.config_load()\n",
    "config_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, y, predictors, scoring='roc_auc', cv=5):\n",
    "    \"\"\"\n",
    "    Perform forward selection procedure to build the best predictive model\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    X : numpy.ndarray\n",
    "        Feature matrix\n",
    "    y : numpy.ndarray\n",
    "        Target variable\n",
    "    predictors : list\n",
    "        List of predictor indices to start the selection from\n",
    "    scoring : str\n",
    "        Scoring metric to evaluate model performance. Default is 'roc_auc'\n",
    "    cv : int\n",
    "        Number of cross-validation folds\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame: Dataframe containing predictors combinations and their cross-validation scores.\n",
    "    pandas.Series: Best model with predictors combination and highest cross-validation score.\n",
    "\n",
    "    This function performs a forward selection procedure to build the best predictive model.\n",
    "    It starts with the initial set of predictors and iteratively adds one predictor at a time, evaluating model performance using cross-validation with the specified scoring metric.\n",
    "    The best model, along with its predictors combination and cross-validation score, is returned.\n",
    "    \"\"\"\n",
    "\n",
    "    #define sample size and  number of all predictors\n",
    "    n_samples, n_predictors = X.shape\n",
    "\n",
    "    #define list of all predictors\n",
    "    col_list = np.arange(n_predictors)\n",
    "\n",
    "    #define remaining predictors for each k\n",
    "    remaining_predictors = [p for p in col_list if p not in predictors]\n",
    "\n",
    "    #initialize list of predictors and its CV Score\n",
    "    pred_list = []\n",
    "    score_list = []\n",
    "\n",
    "    #cross validate each possible combination of remaining predictors\n",
    "    for p in remaining_predictors:\n",
    "        combi = predictors + [p]\n",
    "\n",
    "        #extract predictors combination\n",
    "        X_ = X[:, combi]\n",
    "        y_ = y\n",
    "\n",
    "        #define the estimator\n",
    "        model = LogisticRegression(penalty = None,\n",
    "                                   class_weight = 'balanced')\n",
    "\n",
    "        #cross validate the recall scores of the model\n",
    "        cv_results = cross_validate(estimator = model,\n",
    "                                    X = X_,\n",
    "                                    y = y_,\n",
    "                                    scoring = scoring,\n",
    "                                    cv = cv)\n",
    "\n",
    "        #calculate the average CV/recall score\n",
    "        score_ = np.mean(cv_results['test_score'])\n",
    "\n",
    "        #append predictors combination and its CV Score to the list\n",
    "        pred_list.append(list(combi))\n",
    "        score_list.append(score_)\n",
    "\n",
    "    #tabulate the results\n",
    "    models = pd.DataFrame({\"Predictors\": pred_list,\n",
    "                           \"CV Score\": score_list})\n",
    "\n",
    "    #choose the best model\n",
    "    best_model = models.loc[models['CV Score'].argmax()]\n",
    "\n",
    "    return models, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_forward():\n",
    "    \"\"\"\n",
    "    Perform forward selection on all characteristics to find the best model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame: Dataframe containing predictors combinations and their cross-validation scores.\n",
    "    list: Best predictors (indices) for the best model.\n",
    "\n",
    "    This function performs forward selection on all characteristics to find the best model.\n",
    "    It starts with a null model and iteratively adds predictors while evaluating model performance using cross-validation.\n",
    "    The best model, along with its predictors combination and cross-validation score, is returned. The function also saves the results to files.\n",
    "    \"\"\"\n",
    "\n",
    "    cv = config_data['num_of_cv']\n",
    "    scoring = config_data['scoring']\n",
    "\n",
    "    X_train_woe_path = config_data['X_train_woe_path']\n",
    "    X_train_woe = utils.pickle_load(X_train_woe_path)\n",
    "    X_train = X_train_woe.to_numpy()\n",
    "\n",
    "    y_train_path = config_data['train_path'][1]\n",
    "    y_train = utils.pickle_load(y_train_path)\n",
    "    y_train = y_train.to_numpy()\n",
    "\n",
    "    #define predictor for the null model\n",
    "    predictor = []\n",
    "\n",
    "    #the predictor in the null model is zero values for all predictors\n",
    "    X_null = np.zeros((X_train.shape[0], 1))\n",
    "\n",
    "    #define the estimator\n",
    "    model = LogisticRegression(penalty = None,\n",
    "                               class_weight = 'balanced')\n",
    "\n",
    "    #cross validate\n",
    "    cv_results = cross_validate(estimator = model,\n",
    "                                X = X_null,\n",
    "                                y = y_train,\n",
    "                                cv = cv,\n",
    "                                scoring = scoring)\n",
    "\n",
    "    #calculate the average CV score\n",
    "    score_ = np.mean(cv_results['test_score'])\n",
    "\n",
    "    # Create table for the best model of each k predictors\n",
    "    # Append the results of null model\n",
    "    forward_models = pd.DataFrame({\"Predictors\": [predictor],\n",
    "                                   \"CV Score\": [score_]})\n",
    "\n",
    "    #define list of predictors\n",
    "    predictors = []\n",
    "    n_predictors = X_train.shape[1]\n",
    "\n",
    "    #perform forward selection procedure for k=1,...,n_predictors\n",
    "    for k in range(n_predictors):\n",
    "        _, best_model = forward(X = X_train,\n",
    "                                y = y_train,\n",
    "                                predictors = predictors,\n",
    "                                scoring = scoring,\n",
    "                                cv = cv)\n",
    "\n",
    "        #tabulate the best model of each k predictors\n",
    "        forward_models.loc[k+1] = best_model\n",
    "        predictors = best_model['Predictors']\n",
    "\n",
    "    #find the best CV score\n",
    "    best_idx = forward_models['CV Score'].argmax()\n",
    "    best_cv_score = forward_models['CV Score'].loc[best_idx]\n",
    "    best_predictors = forward_models['Predictors'].loc[best_idx]\n",
    "\n",
    "    #print the summary\n",
    "    print('===================================================')\n",
    "    print('Best index            :', best_idx)\n",
    "    print('Best CV Score         :', best_cv_score)\n",
    "    print('Best predictors (idx) :', best_predictors)\n",
    "    print('Best predictors       :')\n",
    "    print(X_train_woe.columns[best_predictors].tolist())\n",
    "    print('===================================================')\n",
    "\n",
    "    print(forward_models)\n",
    "    print('===================================================')\n",
    "    \n",
    "    forward_models_path = config_data['forward_models_path']\n",
    "    utils.pickle_dump(forward_models, forward_models_path)\n",
    "\n",
    "    best_predictors_path = config_data['best_predictors_path']\n",
    "    utils.pickle_dump(best_predictors, best_predictors_path)\n",
    "\n",
    "    return forward_models, best_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "Best index            : 1\n",
      "Best CV Score         : 0.8228224851103867\n",
      "Best predictors (idx) : [13]\n",
      "Best predictors       :\n",
      "['LoanPurpose']\n",
      "===================================================\n",
      "                                           Predictors  CV Score\n",
      "0                                                  []  0.000000\n",
      "1                                                [13]  0.822822\n",
      "2                                             [13, 6]  0.814099\n",
      "3                                          [13, 6, 9]  0.681563\n",
      "4                                       [13, 6, 9, 0]  0.644424\n",
      "5                                    [13, 6, 9, 0, 1]  0.662087\n",
      "6                                 [13, 6, 9, 0, 1, 5]  0.658883\n",
      "7                              [13, 6, 9, 0, 1, 5, 3]  0.671444\n",
      "8                           [13, 6, 9, 0, 1, 5, 3, 2]  0.678948\n",
      "9                        [13, 6, 9, 0, 1, 5, 3, 2, 4]  0.682488\n",
      "10                   [13, 6, 9, 0, 1, 5, 3, 2, 4, 10]  0.682152\n",
      "11               [13, 6, 9, 0, 1, 5, 3, 2, 4, 10, 11]  0.683753\n",
      "12            [13, 6, 9, 0, 1, 5, 3, 2, 4, 10, 11, 7]  0.683754\n",
      "13         [13, 6, 9, 0, 1, 5, 3, 2, 4, 10, 11, 7, 8]  0.683037\n",
      "14     [13, 6, 9, 0, 1, 5, 3, 2, 4, 10, 11, 7, 8, 12]  0.684723\n",
      "15  [13, 6, 9, 0, 1, 5, 3, 2, 4, 10, 11, 7, 8, 12,...  0.685650\n",
      "===================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                           Predictors  CV Score\n",
       " 0                                                  []  0.000000\n",
       " 1                                                [13]  0.822822\n",
       " 2                                             [13, 6]  0.814099\n",
       " 3                                          [13, 6, 9]  0.681563\n",
       " 4                                       [13, 6, 9, 0]  0.644424\n",
       " 5                                    [13, 6, 9, 0, 1]  0.662087\n",
       " 6                                 [13, 6, 9, 0, 1, 5]  0.658883\n",
       " 7                              [13, 6, 9, 0, 1, 5, 3]  0.671444\n",
       " 8                           [13, 6, 9, 0, 1, 5, 3, 2]  0.678948\n",
       " 9                        [13, 6, 9, 0, 1, 5, 3, 2, 4]  0.682488\n",
       " 10                   [13, 6, 9, 0, 1, 5, 3, 2, 4, 10]  0.682152\n",
       " 11               [13, 6, 9, 0, 1, 5, 3, 2, 4, 10, 11]  0.683753\n",
       " 12            [13, 6, 9, 0, 1, 5, 3, 2, 4, 10, 11, 7]  0.683754\n",
       " 13         [13, 6, 9, 0, 1, 5, 3, 2, 4, 10, 11, 7, 8]  0.683037\n",
       " 14     [13, 6, 9, 0, 1, 5, 3, 2, 4, 10, 11, 7, 8, 12]  0.684723\n",
       " 15  [13, 6, 9, 0, 1, 5, 3, 2, 4, 10, 11, 7, 8, 12,...  0.685650,\n",
       " [13])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the function\n",
    "run_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model_fitting(best_predictors):\n",
    "    \"\"\"\n",
    "    Fit the best model on the whole X_train dataset.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    best_predictors (list): A list of indices representing the best predictors (default: None).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    LogisticRegression: The best logistic regression model.\n",
    "    pandas.DataFrame: Summary of the best model's parameter estimates.\n",
    "\n",
    "    This function fits the best model on the entire X_train dataset based on the best predictors found during forward selection.\n",
    "    It returns the fitted model and a summary of the model's parameter estimates.\n",
    "    If the `best_predictors` argument is not provided, it loads the best predictors from a saved file. The fitted model and summary are also saved to files.\n",
    "    \"\"\"\n",
    "\n",
    "    X_train_path = config_data['X_train_woe_path']\n",
    "    X_train_woe = utils.pickle_load(X_train_path)\n",
    "    X_train = X_train_woe.to_numpy()\n",
    "\n",
    "    y_train_path = config_data['train_path'][1]\n",
    "    y_train = utils.pickle_load(y_train_path)\n",
    "    y_train = y_train.to_numpy()\n",
    "\n",
    "    if best_predictors is None:\n",
    "        best_predictors_path = config_data['best_predictors_path']\n",
    "        best_predictors = utils.pickle_load(best_predictors_path)\n",
    "        print(f\"Best predictors index   :\", best_predictors)\n",
    "    else:\n",
    "        print(f\"[Adjusted] best predictors index   :\", best_predictors)\n",
    "\n",
    "    #define X with best predictors\n",
    "    X_train_best = X_train[:, best_predictors]\n",
    "\n",
    "    #fit best model\n",
    "    best_model = LogisticRegression(penalty = None,\n",
    "                                    class_weight = 'balanced')\n",
    "    best_model.fit(X_train_best, y_train)\n",
    "\n",
    "    print(best_model)\n",
    "\n",
    "    #extract the best model' parameter estimates\n",
    "    best_model_intercept = pd.DataFrame({'Characteristic': 'Intercept',\n",
    "                                         'Estimate': best_model.intercept_})\n",
    "    \n",
    "    best_model_params = X_train_woe.columns[best_predictors].tolist()\n",
    "\n",
    "    best_model_coefs = pd.DataFrame({'Characteristic': best_model_params,\n",
    "                                     'Estimate': np.reshape(best_model.coef_, \n",
    "                                                            len(best_predictors))})\n",
    "\n",
    "    best_model_summary = pd.concat((best_model_intercept, best_model_coefs),\n",
    "                                   axis = 0,\n",
    "                                   ignore_index = True)\n",
    "    \n",
    "    print('===================================================')\n",
    "    print(best_model_summary)\n",
    "    \n",
    "    best_model_path = config_data['best_model_path']\n",
    "    utils.pickle_dump(best_model, best_model_path)\n",
    "\n",
    "    best_model_summary_path = config_data['best_model_summary_path']\n",
    "    utils.pickle_dump(best_model_summary, best_model_summary_path)\n",
    "\n",
    "    return best_model, best_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best predictors index   : [13]\n",
      "LogisticRegression(class_weight='balanced', penalty=None)\n",
      "===================================================\n",
      "  Characteristic      Estimate\n",
      "0      Intercept -6.390458e-14\n",
      "1    LoanPurpose -1.000000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(class_weight='balanced', penalty=None),\n",
       "   Characteristic      Estimate\n",
       " 0      Intercept -6.390458e-14\n",
       " 1    LoanPurpose -1.000000e+00)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the function\n",
    "best_model_fitting(best_predictors = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Adjusted] best predictors index   : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "LogisticRegression(class_weight='balanced', penalty=None)\n",
      "===================================================\n",
      "    Characteristic  Estimate\n",
      "0        Intercept -0.002556\n",
      "1              Age -1.063223\n",
      "2           Income -1.060490\n",
      "3       LoanAmount -1.031861\n",
      "4   MonthsEmployed -1.102113\n",
      "5   NumCreditLines -1.164891\n",
      "6     InterestRate -1.077863\n",
      "7         LoanTerm -0.699679\n",
      "8         DTIRatio -1.051160\n",
      "9        Education -1.171656\n",
      "10  EmploymentType -1.074888\n",
      "11   MaritalStatus -1.001829\n",
      "12     HasMortgage -1.168920\n",
      "13   HasDependents -1.114274\n",
      "14     LoanPurpose -1.148944\n",
      "15     HasCoSigner -1.112417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(class_weight='balanced', penalty=None),\n",
       "     Characteristic  Estimate\n",
       " 0        Intercept -0.002556\n",
       " 1              Age -1.063223\n",
       " 2           Income -1.060490\n",
       " 3       LoanAmount -1.031861\n",
       " 4   MonthsEmployed -1.102113\n",
       " 5   NumCreditLines -1.164891\n",
       " 6     InterestRate -1.077863\n",
       " 7         LoanTerm -0.699679\n",
       " 8         DTIRatio -1.051160\n",
       " 9        Education -1.171656\n",
       " 10  EmploymentType -1.074888\n",
       " 11   MaritalStatus -1.001829\n",
       " 12     HasMortgage -1.168920\n",
       " 13   HasDependents -1.114274\n",
       " 14     LoanPurpose -1.148944\n",
       " 15     HasCoSigner -1.112417)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adjust the best predictors\n",
    "best_model_fitting(best_predictors = np.arange(15).tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
